{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "option_model_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_AdvanceDL_Project/blob/main/models/option_model_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyoLYRx-y8rU",
        "outputId": "8e50d5bf-5553-486f-8442-4c96fd13acd6"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdR7jci04Bv"
      },
      "source": [
        "option = pd.read_csv('/gdrive/My Drive/Data set/Option/WIX_call-options-black-scholes.csv')\n",
        "underlying = pd.read_csv('/gdrive/My Drive/Data set/Option/WIX_underlying.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "UBcPJ3X9PrfB",
        "outputId": "22bb5fe0-5321-43b8-ba75-cbfbd8f23b81"
      },
      "source": [
        "underlying"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DataDate</th>\n",
              "      <th>UnderlyingPrice</th>\n",
              "      <th>sigma_5</th>\n",
              "      <th>sigma_10</th>\n",
              "      <th>sigma_21</th>\n",
              "      <th>sigma_30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>10.98</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/3/2018 04:00:00 PM</td>\n",
              "      <td>11.55</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/4/2018 04:00:00 PM</td>\n",
              "      <td>12.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/5/2018 04:00:00 PM</td>\n",
              "      <td>11.88</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/8/2018 04:00:00 PM</td>\n",
              "      <td>12.28</td>\n",
              "      <td>0.033379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>7/25/2019 04:00:00 PM</td>\n",
              "      <td>33.67</td>\n",
              "      <td>0.015078</td>\n",
              "      <td>0.019606</td>\n",
              "      <td>0.018441</td>\n",
              "      <td>0.022449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>7/26/2019 04:00:00 PM</td>\n",
              "      <td>34.02</td>\n",
              "      <td>0.015076</td>\n",
              "      <td>0.015556</td>\n",
              "      <td>0.017786</td>\n",
              "      <td>0.021421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>7/29/2019 04:00:00 PM</td>\n",
              "      <td>33.48</td>\n",
              "      <td>0.017021</td>\n",
              "      <td>0.015576</td>\n",
              "      <td>0.018002</td>\n",
              "      <td>0.020211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>7/30/2019 04:00:00 PM</td>\n",
              "      <td>33.87</td>\n",
              "      <td>0.014728</td>\n",
              "      <td>0.015906</td>\n",
              "      <td>0.017308</td>\n",
              "      <td>0.018911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>30.45</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.029230</td>\n",
              "      <td>0.027146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>396 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  DataDate  UnderlyingPrice  ...  sigma_21  sigma_30\n",
              "0     1/2/2018 04:00:00 PM            10.98  ...       NaN       NaN\n",
              "1     1/3/2018 04:00:00 PM            11.55  ...       NaN       NaN\n",
              "2     1/4/2018 04:00:00 PM            12.12  ...       NaN       NaN\n",
              "3     1/5/2018 04:00:00 PM            11.88  ...       NaN       NaN\n",
              "4     1/8/2018 04:00:00 PM            12.28  ...       NaN       NaN\n",
              "..                     ...              ...  ...       ...       ...\n",
              "391  7/25/2019 04:00:00 PM            33.67  ...  0.018441  0.022449\n",
              "392  7/26/2019 04:00:00 PM            34.02  ...  0.017786  0.021421\n",
              "393  7/29/2019 04:00:00 PM            33.48  ...  0.018002  0.020211\n",
              "394  7/30/2019 04:00:00 PM            33.87  ...  0.017308  0.018911\n",
              "395  7/31/2019 04:00:00 PM            30.45  ...  0.029230  0.027146\n",
              "\n",
              "[396 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "WMa3C0wj1LwG",
        "outputId": "7d04908e-8e2b-4ccd-9527-2ff6c810e2db"
      },
      "source": [
        "option.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>UnderlyingSymbol</th>\n",
              "      <th>UnderlyingPrice</th>\n",
              "      <th>Exchange</th>\n",
              "      <th>OptionSymbol</th>\n",
              "      <th>Blank</th>\n",
              "      <th>Expiration</th>\n",
              "      <th>DataDate</th>\n",
              "      <th>Strike</th>\n",
              "      <th>Last</th>\n",
              "      <th>Bid</th>\n",
              "      <th>Ask</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInterest</th>\n",
              "      <th>IV</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>Theta</th>\n",
              "      <th>Vega</th>\n",
              "      <th>Alias</th>\n",
              "      <th>sigma_5</th>\n",
              "      <th>sigma_10</th>\n",
              "      <th>sigma_21</th>\n",
              "      <th>sigma_30</th>\n",
              "      <th>date_diff</th>\n",
              "      <th>treasury_rate</th>\n",
              "      <th>black_scholes_pred_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>40.0</td>\n",
              "      <td>17.90</td>\n",
              "      <td>17.00</td>\n",
              "      <td>20.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0474</td>\n",
              "      <td>0.8556</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>-17.1540</td>\n",
              "      <td>2.8402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00045000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>45.0</td>\n",
              "      <td>14.82</td>\n",
              "      <td>11.70</td>\n",
              "      <td>15.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.6263</td>\n",
              "      <td>0.8151</td>\n",
              "      <td>1.3130</td>\n",
              "      <td>-15.9985</td>\n",
              "      <td>3.3340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00050000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.20</td>\n",
              "      <td>7.70</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.9858</td>\n",
              "      <td>0.7884</td>\n",
              "      <td>2.3499</td>\n",
              "      <td>-10.5303</td>\n",
              "      <td>3.6168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00055000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3.60</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>314.0</td>\n",
              "      <td>0.5262</td>\n",
              "      <td>0.6978</td>\n",
              "      <td>5.3048</td>\n",
              "      <td>-6.7828</td>\n",
              "      <td>4.3585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00060000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.45</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.65</td>\n",
              "      <td>181.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>0.5014</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>6.1458</td>\n",
              "      <td>-7.1221</td>\n",
              "      <td>4.8110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... treasury_rate  black_scholes_pred_21\n",
              "0           0             0  ...          1.29                    NaN\n",
              "1           2             2  ...          1.29                    NaN\n",
              "2           4             4  ...          1.29                    NaN\n",
              "3           6             6  ...          1.29                    NaN\n",
              "4           8             8  ...          1.29                    NaN\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "uQ0J7aXw9B4Q",
        "outputId": "a6986caf-690e-49a7-8c39-a7dc9d8a6dc0"
      },
      "source": [
        "option"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>UnderlyingSymbol</th>\n",
              "      <th>UnderlyingPrice</th>\n",
              "      <th>Exchange</th>\n",
              "      <th>OptionSymbol</th>\n",
              "      <th>Blank</th>\n",
              "      <th>Expiration</th>\n",
              "      <th>DataDate</th>\n",
              "      <th>Strike</th>\n",
              "      <th>Last</th>\n",
              "      <th>Bid</th>\n",
              "      <th>Ask</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInterest</th>\n",
              "      <th>IV</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>Theta</th>\n",
              "      <th>Vega</th>\n",
              "      <th>Alias</th>\n",
              "      <th>sigma_5</th>\n",
              "      <th>sigma_10</th>\n",
              "      <th>sigma_21</th>\n",
              "      <th>sigma_30</th>\n",
              "      <th>date_diff</th>\n",
              "      <th>treasury_rate</th>\n",
              "      <th>black_scholes_pred_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>40.0</td>\n",
              "      <td>17.90</td>\n",
              "      <td>17.00</td>\n",
              "      <td>20.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0474</td>\n",
              "      <td>0.8556</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>-17.1540</td>\n",
              "      <td>2.8402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00045000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>45.0</td>\n",
              "      <td>14.82</td>\n",
              "      <td>11.70</td>\n",
              "      <td>15.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.6263</td>\n",
              "      <td>0.8151</td>\n",
              "      <td>1.3130</td>\n",
              "      <td>-15.9985</td>\n",
              "      <td>3.3340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00050000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.20</td>\n",
              "      <td>7.70</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.9858</td>\n",
              "      <td>0.7884</td>\n",
              "      <td>2.3499</td>\n",
              "      <td>-10.5303</td>\n",
              "      <td>3.6168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00055000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3.60</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>314.0</td>\n",
              "      <td>0.5262</td>\n",
              "      <td>0.6978</td>\n",
              "      <td>5.3048</td>\n",
              "      <td>-6.7828</td>\n",
              "      <td>4.3585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00060000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.45</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.65</td>\n",
              "      <td>181.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>0.5014</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>6.1458</td>\n",
              "      <td>-7.1221</td>\n",
              "      <td>4.8110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51487</th>\n",
              "      <td>103562</td>\n",
              "      <td>103562</td>\n",
              "      <td>WIX</td>\n",
              "      <td>148.52</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX210115C00185000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/15/2021</td>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>185.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16.40</td>\n",
              "      <td>19.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4199</td>\n",
              "      <td>0.4462</td>\n",
              "      <td>0.5241</td>\n",
              "      <td>-2.9859</td>\n",
              "      <td>71.0047</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.02923</td>\n",
              "      <td>0.027146</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.659971e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51488</th>\n",
              "      <td>103564</td>\n",
              "      <td>103564</td>\n",
              "      <td>WIX</td>\n",
              "      <td>148.52</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX210115C00190000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/15/2021</td>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>190.0</td>\n",
              "      <td>15.33</td>\n",
              "      <td>15.00</td>\n",
              "      <td>17.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.4175</td>\n",
              "      <td>0.4239</td>\n",
              "      <td>0.5223</td>\n",
              "      <td>-2.9365</td>\n",
              "      <td>70.3513</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.02923</td>\n",
              "      <td>0.027146</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.771637e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51489</th>\n",
              "      <td>103566</td>\n",
              "      <td>103566</td>\n",
              "      <td>WIX</td>\n",
              "      <td>148.52</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX210115C00195000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/15/2021</td>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>195.0</td>\n",
              "      <td>13.40</td>\n",
              "      <td>13.90</td>\n",
              "      <td>16.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4139</td>\n",
              "      <td>0.4014</td>\n",
              "      <td>0.5201</td>\n",
              "      <td>-2.8700</td>\n",
              "      <td>69.4568</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.02923</td>\n",
              "      <td>0.027146</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.594149e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51490</th>\n",
              "      <td>103568</td>\n",
              "      <td>103568</td>\n",
              "      <td>WIX</td>\n",
              "      <td>148.52</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX210115C00200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/15/2021</td>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>200.0</td>\n",
              "      <td>11.80</td>\n",
              "      <td>12.90</td>\n",
              "      <td>15.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.4120</td>\n",
              "      <td>0.3805</td>\n",
              "      <td>0.5147</td>\n",
              "      <td>-2.8101</td>\n",
              "      <td>68.4214</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.02923</td>\n",
              "      <td>0.027146</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.226700e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51491</th>\n",
              "      <td>103570</td>\n",
              "      <td>103570</td>\n",
              "      <td>WIX</td>\n",
              "      <td>148.52</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX210115C00210000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/15/2021</td>\n",
              "      <td>7/31/2019 04:00:00 PM</td>\n",
              "      <td>210.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>10.10</td>\n",
              "      <td>13.20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.4110</td>\n",
              "      <td>0.3430</td>\n",
              "      <td>0.4980</td>\n",
              "      <td>-2.6967</td>\n",
              "      <td>66.0350</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.053055</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.02923</td>\n",
              "      <td>0.027146</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>9.948072e-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51492 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1  ... treasury_rate  black_scholes_pred_21\n",
              "0               0             0  ...          1.29                    NaN\n",
              "1               2             2  ...          1.29                    NaN\n",
              "2               4             4  ...          1.29                    NaN\n",
              "3               6             6  ...          1.29                    NaN\n",
              "4               8             8  ...          1.29                    NaN\n",
              "...           ...           ...  ...           ...                    ...\n",
              "51487      103562        103562  ...          2.00           3.659971e-08\n",
              "51488      103564        103564  ...          2.00           3.771637e-10\n",
              "51489      103566        103566  ...          2.00           2.594149e-12\n",
              "51490      103568        103568  ...          2.00           1.226700e-14\n",
              "51491      103570        103570  ...          2.00           9.948072e-20\n",
              "\n",
              "[51492 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWDjOZGgCAt1",
        "outputId": "9f09ea7d-7ccd-4a77-f4b1-60025a29d53e"
      },
      "source": [
        "option.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51492 entries, 0 to 51491\n",
            "Data columns (total 28 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Unnamed: 0             51492 non-null  int64  \n",
            " 1   Unnamed: 0.1           51492 non-null  int64  \n",
            " 2   UnderlyingSymbol       51492 non-null  object \n",
            " 3   UnderlyingPrice        51492 non-null  float64\n",
            " 4   Exchange               51492 non-null  object \n",
            " 5   OptionSymbol           51492 non-null  object \n",
            " 6   Blank                  0 non-null      float64\n",
            " 7   Expiration             51492 non-null  object \n",
            " 8   DataDate               51492 non-null  object \n",
            " 9   Strike                 51492 non-null  float64\n",
            " 10  Last                   51492 non-null  float64\n",
            " 11  Bid                    51492 non-null  float64\n",
            " 12  Ask                    51492 non-null  float64\n",
            " 13  Volume                 51492 non-null  float64\n",
            " 14  OpenInterest           51492 non-null  float64\n",
            " 15  IV                     51492 non-null  float64\n",
            " 16  Delta                  51492 non-null  float64\n",
            " 17  Gamma                  51492 non-null  float64\n",
            " 18  Theta                  51492 non-null  float64\n",
            " 19  Vega                   51492 non-null  float64\n",
            " 20  Alias                  0 non-null      float64\n",
            " 21  sigma_5                51156 non-null  float64\n",
            " 22  sigma_10               50736 non-null  float64\n",
            " 23  sigma_21               49833 non-null  float64\n",
            " 24  sigma_30               49104 non-null  float64\n",
            " 25  date_diff              51492 non-null  int64  \n",
            " 26  treasury_rate          51492 non-null  float64\n",
            " 27  black_scholes_pred_21  49831 non-null  float64\n",
            "dtypes: float64(20), int64(3), object(5)\n",
            "memory usage: 11.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCgAs5D9U0D"
      },
      "source": [
        "call_df = option"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyL-nSq6PCmY"
      },
      "source": [
        "N_TIMESTEPS = 21\n",
        "padded = np.insert(underlying.UnderlyingPrice.values, 0, np.array([np.nan] * N_TIMESTEPS))\n",
        "rolled = np.column_stack([np.roll(padded, i) for i in range(N_TIMESTEPS)])\n",
        "rolled = rolled[~np.isnan(rolled).any(axis=1)]\n",
        "rolled = np.column_stack((underlying.DataDate.values[N_TIMESTEPS - 1:], rolled))\n",
        "price_history = pd.DataFrame(data=rolled)\n",
        "joined = option.join(price_history.set_index(0), on='DataDate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tp4dNPTQMsd",
        "outputId": "150d19b6-74f0-43ba-ba4c-22a474610b54"
      },
      "source": [
        "joined.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51492, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "5O0KoxawQT3N",
        "outputId": "99d5a12f-6171-4622-fb6a-96193887ecf7"
      },
      "source": [
        "joined.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>UnderlyingSymbol</th>\n",
              "      <th>UnderlyingPrice</th>\n",
              "      <th>Exchange</th>\n",
              "      <th>OptionSymbol</th>\n",
              "      <th>Blank</th>\n",
              "      <th>Expiration</th>\n",
              "      <th>DataDate</th>\n",
              "      <th>Strike</th>\n",
              "      <th>Last</th>\n",
              "      <th>Bid</th>\n",
              "      <th>Ask</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInterest</th>\n",
              "      <th>IV</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>Theta</th>\n",
              "      <th>Vega</th>\n",
              "      <th>Alias</th>\n",
              "      <th>sigma_5</th>\n",
              "      <th>sigma_10</th>\n",
              "      <th>sigma_21</th>\n",
              "      <th>sigma_30</th>\n",
              "      <th>date_diff</th>\n",
              "      <th>treasury_rate</th>\n",
              "      <th>black_scholes_pred_21</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>40.0</td>\n",
              "      <td>17.90</td>\n",
              "      <td>17.00</td>\n",
              "      <td>20.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0474</td>\n",
              "      <td>0.8556</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>-17.1540</td>\n",
              "      <td>2.8402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00045000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>45.0</td>\n",
              "      <td>14.82</td>\n",
              "      <td>11.70</td>\n",
              "      <td>15.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.6263</td>\n",
              "      <td>0.8151</td>\n",
              "      <td>1.3130</td>\n",
              "      <td>-15.9985</td>\n",
              "      <td>3.3340</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00050000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.20</td>\n",
              "      <td>7.70</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.9858</td>\n",
              "      <td>0.7884</td>\n",
              "      <td>2.3499</td>\n",
              "      <td>-10.5303</td>\n",
              "      <td>3.6168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00055000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3.60</td>\n",
              "      <td>4.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>314.0</td>\n",
              "      <td>0.5262</td>\n",
              "      <td>0.6978</td>\n",
              "      <td>5.3048</td>\n",
              "      <td>-6.7828</td>\n",
              "      <td>4.3585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>WIX</td>\n",
              "      <td>57.95</td>\n",
              "      <td>*</td>\n",
              "      <td>WIX180119C00060000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>01/19/2018</td>\n",
              "      <td>1/2/2018 04:00:00 PM</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.45</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.65</td>\n",
              "      <td>181.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>0.5014</td>\n",
              "      <td>0.3950</td>\n",
              "      <td>6.1458</td>\n",
              "      <td>-7.1221</td>\n",
              "      <td>4.8110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1 UnderlyingSymbol  ...   19   20   21\n",
              "0           0             0              WIX  ...  NaN  NaN  NaN\n",
              "1           2             2              WIX  ...  NaN  NaN  NaN\n",
              "2           4             4              WIX  ...  NaN  NaN  NaN\n",
              "3           6             6              WIX  ...  NaN  NaN  NaN\n",
              "4           8             8              WIX  ...  NaN  NaN  NaN\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7dWby79Q8NP"
      },
      "source": [
        "option = joined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OLx-XzYQ6BG"
      },
      "source": [
        "option = option.drop(columns=['Unnamed: 0','Unnamed: 0.1','UnderlyingSymbol','Exchange','OptionSymbol','Blank','Expiration',\n",
        "                     'DataDate','Last','Volume','OpenInterest','IV','Delta','Gamma','Theta','Vega','Alias',\n",
        "                     'sigma_5','sigma_10','sigma_21','sigma_30'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZEd9WmpRFq2"
      },
      "source": [
        "option = option.drop(columns=['black_scholes_pred_21'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCI5-fKyRAPB"
      },
      "source": [
        "call_df = option"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYsLSa4WcSw"
      },
      "source": [
        "call_df = call_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Mfo_Jw80Wgms",
        "outputId": "a527698f-88e0-4c02-e1dd-0f98382cf8ed"
      },
      "source": [
        "call_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UnderlyingPrice</th>\n",
              "      <th>Strike</th>\n",
              "      <th>Bid</th>\n",
              "      <th>Ask</th>\n",
              "      <th>date_diff</th>\n",
              "      <th>treasury_rate</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>61.05</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.3</td>\n",
              "      <td>31.8</td>\n",
              "      <td>16</td>\n",
              "      <td>1.43</td>\n",
              "      <td>13.735</td>\n",
              "      <td>12.865</td>\n",
              "      <td>13.32</td>\n",
              "      <td>12.95</td>\n",
              "      <td>12.41</td>\n",
              "      <td>12.71</td>\n",
              "      <td>12.94</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.59</td>\n",
              "      <td>12.47</td>\n",
              "      <td>12.18</td>\n",
              "      <td>11.91</td>\n",
              "      <td>12.02</td>\n",
              "      <td>12.1404</td>\n",
              "      <td>11.96</td>\n",
              "      <td>11.82</td>\n",
              "      <td>12.28</td>\n",
              "      <td>11.88</td>\n",
              "      <td>12.12</td>\n",
              "      <td>11.55</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1660</th>\n",
              "      <td>61.05</td>\n",
              "      <td>35.0</td>\n",
              "      <td>25.3</td>\n",
              "      <td>26.9</td>\n",
              "      <td>16</td>\n",
              "      <td>1.43</td>\n",
              "      <td>13.735</td>\n",
              "      <td>12.865</td>\n",
              "      <td>13.32</td>\n",
              "      <td>12.95</td>\n",
              "      <td>12.41</td>\n",
              "      <td>12.71</td>\n",
              "      <td>12.94</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.59</td>\n",
              "      <td>12.47</td>\n",
              "      <td>12.18</td>\n",
              "      <td>11.91</td>\n",
              "      <td>12.02</td>\n",
              "      <td>12.1404</td>\n",
              "      <td>11.96</td>\n",
              "      <td>11.82</td>\n",
              "      <td>12.28</td>\n",
              "      <td>11.88</td>\n",
              "      <td>12.12</td>\n",
              "      <td>11.55</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>61.05</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.4</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16</td>\n",
              "      <td>1.43</td>\n",
              "      <td>13.735</td>\n",
              "      <td>12.865</td>\n",
              "      <td>13.32</td>\n",
              "      <td>12.95</td>\n",
              "      <td>12.41</td>\n",
              "      <td>12.71</td>\n",
              "      <td>12.94</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.59</td>\n",
              "      <td>12.47</td>\n",
              "      <td>12.18</td>\n",
              "      <td>11.91</td>\n",
              "      <td>12.02</td>\n",
              "      <td>12.1404</td>\n",
              "      <td>11.96</td>\n",
              "      <td>11.82</td>\n",
              "      <td>12.28</td>\n",
              "      <td>11.88</td>\n",
              "      <td>12.12</td>\n",
              "      <td>11.55</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>61.05</td>\n",
              "      <td>45.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>16.7</td>\n",
              "      <td>16</td>\n",
              "      <td>1.43</td>\n",
              "      <td>13.735</td>\n",
              "      <td>12.865</td>\n",
              "      <td>13.32</td>\n",
              "      <td>12.95</td>\n",
              "      <td>12.41</td>\n",
              "      <td>12.71</td>\n",
              "      <td>12.94</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.59</td>\n",
              "      <td>12.47</td>\n",
              "      <td>12.18</td>\n",
              "      <td>11.91</td>\n",
              "      <td>12.02</td>\n",
              "      <td>12.1404</td>\n",
              "      <td>11.96</td>\n",
              "      <td>11.82</td>\n",
              "      <td>12.28</td>\n",
              "      <td>11.88</td>\n",
              "      <td>12.12</td>\n",
              "      <td>11.55</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>61.05</td>\n",
              "      <td>50.0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>12.2</td>\n",
              "      <td>16</td>\n",
              "      <td>1.43</td>\n",
              "      <td>13.735</td>\n",
              "      <td>12.865</td>\n",
              "      <td>13.32</td>\n",
              "      <td>12.95</td>\n",
              "      <td>12.41</td>\n",
              "      <td>12.71</td>\n",
              "      <td>12.94</td>\n",
              "      <td>12.64</td>\n",
              "      <td>12.59</td>\n",
              "      <td>12.47</td>\n",
              "      <td>12.18</td>\n",
              "      <td>11.91</td>\n",
              "      <td>12.02</td>\n",
              "      <td>12.1404</td>\n",
              "      <td>11.96</td>\n",
              "      <td>11.82</td>\n",
              "      <td>12.28</td>\n",
              "      <td>11.88</td>\n",
              "      <td>12.12</td>\n",
              "      <td>11.55</td>\n",
              "      <td>10.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51487</th>\n",
              "      <td>148.52</td>\n",
              "      <td>185.0</td>\n",
              "      <td>16.4</td>\n",
              "      <td>19.2</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>30.45</td>\n",
              "      <td>33.87</td>\n",
              "      <td>33.48</td>\n",
              "      <td>34.02</td>\n",
              "      <td>33.67</td>\n",
              "      <td>34.11</td>\n",
              "      <td>33.49</td>\n",
              "      <td>32.85</td>\n",
              "      <td>32.51</td>\n",
              "      <td>33</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.85</td>\n",
              "      <td>34.39</td>\n",
              "      <td>33.21</td>\n",
              "      <td>33.06</td>\n",
              "      <td>33.79</td>\n",
              "      <td>33.15</td>\n",
              "      <td>32.04</td>\n",
              "      <td>31.5</td>\n",
              "      <td>31.19</td>\n",
              "      <td>31.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51488</th>\n",
              "      <td>148.52</td>\n",
              "      <td>190.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>30.45</td>\n",
              "      <td>33.87</td>\n",
              "      <td>33.48</td>\n",
              "      <td>34.02</td>\n",
              "      <td>33.67</td>\n",
              "      <td>34.11</td>\n",
              "      <td>33.49</td>\n",
              "      <td>32.85</td>\n",
              "      <td>32.51</td>\n",
              "      <td>33</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.85</td>\n",
              "      <td>34.39</td>\n",
              "      <td>33.21</td>\n",
              "      <td>33.06</td>\n",
              "      <td>33.79</td>\n",
              "      <td>33.15</td>\n",
              "      <td>32.04</td>\n",
              "      <td>31.5</td>\n",
              "      <td>31.19</td>\n",
              "      <td>31.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51489</th>\n",
              "      <td>148.52</td>\n",
              "      <td>195.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>16.4</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>30.45</td>\n",
              "      <td>33.87</td>\n",
              "      <td>33.48</td>\n",
              "      <td>34.02</td>\n",
              "      <td>33.67</td>\n",
              "      <td>34.11</td>\n",
              "      <td>33.49</td>\n",
              "      <td>32.85</td>\n",
              "      <td>32.51</td>\n",
              "      <td>33</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.85</td>\n",
              "      <td>34.39</td>\n",
              "      <td>33.21</td>\n",
              "      <td>33.06</td>\n",
              "      <td>33.79</td>\n",
              "      <td>33.15</td>\n",
              "      <td>32.04</td>\n",
              "      <td>31.5</td>\n",
              "      <td>31.19</td>\n",
              "      <td>31.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51490</th>\n",
              "      <td>148.52</td>\n",
              "      <td>200.0</td>\n",
              "      <td>12.9</td>\n",
              "      <td>15.2</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>30.45</td>\n",
              "      <td>33.87</td>\n",
              "      <td>33.48</td>\n",
              "      <td>34.02</td>\n",
              "      <td>33.67</td>\n",
              "      <td>34.11</td>\n",
              "      <td>33.49</td>\n",
              "      <td>32.85</td>\n",
              "      <td>32.51</td>\n",
              "      <td>33</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.85</td>\n",
              "      <td>34.39</td>\n",
              "      <td>33.21</td>\n",
              "      <td>33.06</td>\n",
              "      <td>33.79</td>\n",
              "      <td>33.15</td>\n",
              "      <td>32.04</td>\n",
              "      <td>31.5</td>\n",
              "      <td>31.19</td>\n",
              "      <td>31.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51491</th>\n",
              "      <td>148.52</td>\n",
              "      <td>210.0</td>\n",
              "      <td>10.1</td>\n",
              "      <td>13.2</td>\n",
              "      <td>534</td>\n",
              "      <td>2.00</td>\n",
              "      <td>30.45</td>\n",
              "      <td>33.87</td>\n",
              "      <td>33.48</td>\n",
              "      <td>34.02</td>\n",
              "      <td>33.67</td>\n",
              "      <td>34.11</td>\n",
              "      <td>33.49</td>\n",
              "      <td>32.85</td>\n",
              "      <td>32.51</td>\n",
              "      <td>33</td>\n",
              "      <td>33.6</td>\n",
              "      <td>33.85</td>\n",
              "      <td>34.39</td>\n",
              "      <td>33.21</td>\n",
              "      <td>33.06</td>\n",
              "      <td>33.79</td>\n",
              "      <td>33.15</td>\n",
              "      <td>32.04</td>\n",
              "      <td>31.5</td>\n",
              "      <td>31.19</td>\n",
              "      <td>31.24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49833 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       UnderlyingPrice  Strike   Bid   Ask  ...     18     19     20     21\n",
              "1659             61.05    30.0  30.3  31.8  ...  11.88  12.12  11.55  10.98\n",
              "1660             61.05    35.0  25.3  26.9  ...  11.88  12.12  11.55  10.98\n",
              "1661             61.05    40.0  20.4  22.0  ...  11.88  12.12  11.55  10.98\n",
              "1662             61.05    45.0  15.3  16.7  ...  11.88  12.12  11.55  10.98\n",
              "1663             61.05    50.0  10.8  12.2  ...  11.88  12.12  11.55  10.98\n",
              "...                ...     ...   ...   ...  ...    ...    ...    ...    ...\n",
              "51487           148.52   185.0  16.4  19.2  ...  32.04   31.5  31.19  31.24\n",
              "51488           148.52   190.0  15.0  17.8  ...  32.04   31.5  31.19  31.24\n",
              "51489           148.52   195.0  13.9  16.4  ...  32.04   31.5  31.19  31.24\n",
              "51490           148.52   200.0  12.9  15.2  ...  32.04   31.5  31.19  31.24\n",
              "51491           148.52   210.0  10.1  13.2  ...  32.04   31.5  31.19  31.24\n",
              "\n",
              "[49833 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27XntRZ4Zc8J",
        "outputId": "0456e391-51e6-481f-c67f-d460da4f9526"
      },
      "source": [
        "call_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49833 entries, 1659 to 51491\n",
            "Data columns (total 27 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   UnderlyingPrice  49833 non-null  float64\n",
            " 1   Strike           49833 non-null  float64\n",
            " 2   Bid              49833 non-null  float64\n",
            " 3   Ask              49833 non-null  float64\n",
            " 4   date_diff        49833 non-null  int64  \n",
            " 5   treasury_rate    49833 non-null  float64\n",
            " 6   1                49833 non-null  object \n",
            " 7   2                49833 non-null  object \n",
            " 8   3                49833 non-null  object \n",
            " 9   4                49833 non-null  object \n",
            " 10  5                49833 non-null  object \n",
            " 11  6                49833 non-null  object \n",
            " 12  7                49833 non-null  object \n",
            " 13  8                49833 non-null  object \n",
            " 14  9                49833 non-null  object \n",
            " 15  10               49833 non-null  object \n",
            " 16  11               49833 non-null  object \n",
            " 17  12               49833 non-null  object \n",
            " 18  13               49833 non-null  object \n",
            " 19  14               49833 non-null  object \n",
            " 20  15               49833 non-null  object \n",
            " 21  16               49833 non-null  object \n",
            " 22  17               49833 non-null  object \n",
            " 23  18               49833 non-null  object \n",
            " 24  19               49833 non-null  object \n",
            " 25  20               49833 non-null  object \n",
            " 26  21               49833 non-null  object \n",
            "dtypes: float64(5), int64(1), object(21)\n",
            "memory usage: 10.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYh-7YNcZjVN",
        "outputId": "a837eec0-a49e-41c6-b7b3-c366c54facf2"
      },
      "source": [
        "for i in range(1,22):\n",
        "  call_df[i] = call_df[i].astype('float64')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycEeQxQVaXvx",
        "outputId": "46dfa041-1cfe-48f1-c87e-a387c408032e"
      },
      "source": [
        "call_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49833 entries, 1659 to 51491\n",
            "Data columns (total 27 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   UnderlyingPrice  49833 non-null  float64\n",
            " 1   Strike           49833 non-null  float64\n",
            " 2   Bid              49833 non-null  float64\n",
            " 3   Ask              49833 non-null  float64\n",
            " 4   date_diff        49833 non-null  int64  \n",
            " 5   treasury_rate    49833 non-null  float64\n",
            " 6   1                49833 non-null  float64\n",
            " 7   2                49833 non-null  float64\n",
            " 8   3                49833 non-null  float64\n",
            " 9   4                49833 non-null  float64\n",
            " 10  5                49833 non-null  float64\n",
            " 11  6                49833 non-null  float64\n",
            " 12  7                49833 non-null  float64\n",
            " 13  8                49833 non-null  float64\n",
            " 14  9                49833 non-null  float64\n",
            " 15  10               49833 non-null  float64\n",
            " 16  11               49833 non-null  float64\n",
            " 17  12               49833 non-null  float64\n",
            " 18  13               49833 non-null  float64\n",
            " 19  14               49833 non-null  float64\n",
            " 20  15               49833 non-null  float64\n",
            " 21  16               49833 non-null  float64\n",
            " 22  17               49833 non-null  float64\n",
            " 23  18               49833 non-null  float64\n",
            " 24  19               49833 non-null  float64\n",
            " 25  20               49833 non-null  float64\n",
            " 26  21               49833 non-null  float64\n",
            "dtypes: float64(26), int64(1)\n",
            "memory usage: 10.6 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BlNUqio9k8R"
      },
      "source": [
        "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(['Bid', 'Ask'], axis=1).values,\n",
        "                                                                        ((call_df.Bid + call_df.Ask) / 2).values,\n",
        "                                                                        test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT4je1pkLnnC",
        "outputId": "f14d1b75-08e2-4e10-89cb-96613e27de3d"
      },
      "source": [
        "call_X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39866, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHaX3X74RX_J"
      },
      "source": [
        "call_X_train = [call_X_train[:, -N_TIMESTEPS:].reshape(call_X_train.shape[0], N_TIMESTEPS, 1), call_X_train[:, :4]]\n",
        "call_X_test = [call_X_test[:, -N_TIMESTEPS:].reshape(call_X_test.shape[0], N_TIMESTEPS, 1), call_X_test[:, :4]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpRJxwo9-uc"
      },
      "source": [
        "layers = 4\n",
        "n_timesteps = 60\n",
        "features = 4\n",
        "n_batch = 256\n",
        "n_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3YPp1UL-Lev"
      },
      "source": [
        "\n",
        "def make_model():\n",
        "    close_history = Input((N_TIMESTEPS, 1))\n",
        "    input2 = Input((features,))\n",
        "    \n",
        "    lstm = Sequential()\n",
        "    lstm.add(LSTM(units=8, input_shape=(N_TIMESTEPS, 1), return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=False))\n",
        "    input1 = lstm(close_history)\n",
        "    \n",
        "    connect = Concatenate()([input1, input2])\n",
        "    \n",
        "    for _ in range(layers - 1):\n",
        "        connect = Dense(100)(connect)\n",
        "        connect = BatchNormalization()(connect)\n",
        "        connect = LeakyReLU()(connect)\n",
        "    \n",
        "    predict = Dense(1, activation='relu')(connect)\n",
        "\n",
        "    return Model(inputs=[close_history, input2], outputs=predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT9CWWIP-No6"
      },
      "source": [
        "call_model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJCwUcvw-cNB",
        "outputId": "389ea6dd-35c1-485e-af7a-9c3878322394"
      },
      "source": [
        "call_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 21, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_6 (Sequential)       (None, 8)            1952        input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 12)           0           sequential_6[0][0]               \n",
            "                                                                 input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 100)          1300        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 100)          400         dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 100)          0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 100)          10100       leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 100)          400         dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 100)          0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 100)          10100       leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 100)          400         dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 100)          0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 1)            101         leaky_re_lu_20[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 24,753\n",
            "Trainable params: 24,153\n",
            "Non-trainable params: 600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAB3ggsM__0e",
        "outputId": "f51f0c03-5e8d-433a-a8c9-5b166ed15dd1"
      },
      "source": [
        "call_model.compile(optimizer=Adam(lr=1e-3), loss='mse')\n",
        "history = call_model.fit(call_X_train, call_y_train, \n",
        "                    batch_size=n_batch, epochs=400, \n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "  2/155 [..............................] - ETA: 30s - loss: 5.6702WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0452s vs `on_train_batch_end` time: 0.3583s). Check your callbacks.\n",
            "155/155 [==============================] - 7s 45ms/step - loss: 2.2339 - val_loss: 0.5369\n",
            "Epoch 2/400\n",
            "155/155 [==============================] - 6s 37ms/step - loss: 2.2536 - val_loss: 0.5767\n",
            "Epoch 3/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.2771 - val_loss: 1.1630\n",
            "Epoch 4/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0542 - val_loss: 0.9588\n",
            "Epoch 5/400\n",
            "155/155 [==============================] - 6s 37ms/step - loss: 2.1497 - val_loss: 0.8562\n",
            "Epoch 6/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0890 - val_loss: 0.7889\n",
            "Epoch 7/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9059 - val_loss: 0.6526\n",
            "Epoch 8/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9993 - val_loss: 0.5785\n",
            "Epoch 9/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.9994 - val_loss: 0.4241\n",
            "Epoch 10/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1474 - val_loss: 0.8219\n",
            "Epoch 11/400\n",
            "155/155 [==============================] - 7s 42ms/step - loss: 2.1183 - val_loss: 0.5584\n",
            "Epoch 12/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6202 - val_loss: 0.4900\n",
            "Epoch 13/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0844 - val_loss: 0.5369\n",
            "Epoch 14/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1804 - val_loss: 0.7430\n",
            "Epoch 15/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0901 - val_loss: 0.4361\n",
            "Epoch 16/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.6689 - val_loss: 0.9843\n",
            "Epoch 17/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.7631 - val_loss: 0.3694\n",
            "Epoch 18/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1375 - val_loss: 1.1537\n",
            "Epoch 19/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6701 - val_loss: 0.7191\n",
            "Epoch 20/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1134 - val_loss: 0.7706\n",
            "Epoch 21/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9103 - val_loss: 0.7977\n",
            "Epoch 22/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.2389 - val_loss: 0.6460\n",
            "Epoch 23/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8937 - val_loss: 0.4493\n",
            "Epoch 24/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0940 - val_loss: 0.6730\n",
            "Epoch 25/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.2049 - val_loss: 0.3719\n",
            "Epoch 26/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9189 - val_loss: 0.5189\n",
            "Epoch 27/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1129 - val_loss: 0.6223\n",
            "Epoch 28/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0067 - val_loss: 0.3807\n",
            "Epoch 29/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.2989 - val_loss: 0.3629\n",
            "Epoch 30/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8776 - val_loss: 0.5044\n",
            "Epoch 31/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.3901 - val_loss: 0.7795\n",
            "Epoch 32/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1262 - val_loss: 1.5887\n",
            "Epoch 33/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 2.4482 - val_loss: 0.7696\n",
            "Epoch 34/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.5258 - val_loss: 0.5153\n",
            "Epoch 35/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.3180 - val_loss: 0.6622\n",
            "Epoch 36/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0664 - val_loss: 0.4692\n",
            "Epoch 37/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.9376 - val_loss: 0.9793\n",
            "Epoch 38/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0798 - val_loss: 0.6032\n",
            "Epoch 39/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1393 - val_loss: 0.4420\n",
            "Epoch 40/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1358 - val_loss: 0.5132\n",
            "Epoch 41/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1940 - val_loss: 0.4135\n",
            "Epoch 42/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8787 - val_loss: 0.4070\n",
            "Epoch 43/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1261 - val_loss: 0.4191\n",
            "Epoch 44/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8330 - val_loss: 0.4865\n",
            "Epoch 45/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9146 - val_loss: 0.4771\n",
            "Epoch 46/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7607 - val_loss: 0.7733\n",
            "Epoch 47/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.9580 - val_loss: 0.4438\n",
            "Epoch 48/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1247 - val_loss: 0.4689\n",
            "Epoch 49/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8186 - val_loss: 0.7298\n",
            "Epoch 50/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.3151 - val_loss: 0.5932\n",
            "Epoch 51/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9758 - val_loss: 0.4659\n",
            "Epoch 52/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7564 - val_loss: 0.7666\n",
            "Epoch 53/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0471 - val_loss: 0.6000\n",
            "Epoch 54/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0066 - val_loss: 0.6721\n",
            "Epoch 55/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.9065 - val_loss: 0.4087\n",
            "Epoch 56/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 2.0888 - val_loss: 0.6264\n",
            "Epoch 57/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8534 - val_loss: 0.6374\n",
            "Epoch 58/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1469 - val_loss: 0.8779\n",
            "Epoch 59/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0669 - val_loss: 0.4584\n",
            "Epoch 60/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0066 - val_loss: 0.4181\n",
            "Epoch 61/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9960 - val_loss: 0.5198\n",
            "Epoch 62/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8387 - val_loss: 0.6316\n",
            "Epoch 63/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7077 - val_loss: 0.5686\n",
            "Epoch 64/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.4078 - val_loss: 0.6171\n",
            "Epoch 65/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9473 - val_loss: 0.5240\n",
            "Epoch 66/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0414 - val_loss: 0.8138\n",
            "Epoch 67/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.2792 - val_loss: 1.2555\n",
            "Epoch 68/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.8898 - val_loss: 0.5662\n",
            "Epoch 69/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3921 - val_loss: 0.3768\n",
            "Epoch 70/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.2883 - val_loss: 0.4794\n",
            "Epoch 71/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6089 - val_loss: 0.4006\n",
            "Epoch 72/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1140 - val_loss: 0.5523\n",
            "Epoch 73/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1683 - val_loss: 0.9612\n",
            "Epoch 74/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8045 - val_loss: 0.6264\n",
            "Epoch 75/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.6181 - val_loss: 0.5130\n",
            "Epoch 76/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.3514 - val_loss: 0.5156\n",
            "Epoch 77/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7917 - val_loss: 0.8765\n",
            "Epoch 78/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1433 - val_loss: 0.4147\n",
            "Epoch 79/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7447 - val_loss: 0.4362\n",
            "Epoch 80/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.7718 - val_loss: 0.5175\n",
            "Epoch 81/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.1011 - val_loss: 0.3851\n",
            "Epoch 82/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.2056 - val_loss: 0.4676\n",
            "Epoch 83/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.0819 - val_loss: 0.4822\n",
            "Epoch 84/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8348 - val_loss: 0.3274\n",
            "Epoch 85/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9581 - val_loss: 0.3621\n",
            "Epoch 86/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1636 - val_loss: 1.2926\n",
            "Epoch 87/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1177 - val_loss: 0.6693\n",
            "Epoch 88/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.9328 - val_loss: 0.6432\n",
            "Epoch 89/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0202 - val_loss: 0.3375\n",
            "Epoch 90/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 2.2823 - val_loss: 0.7185\n",
            "Epoch 91/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 2.1754 - val_loss: 0.3103\n",
            "Epoch 92/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9437 - val_loss: 0.3703\n",
            "Epoch 93/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1911 - val_loss: 0.4713\n",
            "Epoch 94/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8518 - val_loss: 0.4954\n",
            "Epoch 95/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6941 - val_loss: 1.2243\n",
            "Epoch 96/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7643 - val_loss: 0.6405\n",
            "Epoch 97/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0729 - val_loss: 0.6490\n",
            "Epoch 98/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8574 - val_loss: 0.6813\n",
            "Epoch 99/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7826 - val_loss: 0.6928\n",
            "Epoch 100/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7934 - val_loss: 0.5125\n",
            "Epoch 101/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1572 - val_loss: 0.4168\n",
            "Epoch 102/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9449 - val_loss: 0.3720\n",
            "Epoch 103/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8825 - val_loss: 0.9216\n",
            "Epoch 104/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5447 - val_loss: 1.0094\n",
            "Epoch 105/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.2187 - val_loss: 0.5678\n",
            "Epoch 106/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0844 - val_loss: 0.3706\n",
            "Epoch 107/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1807 - val_loss: 0.5135\n",
            "Epoch 108/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9396 - val_loss: 0.4734\n",
            "Epoch 109/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6458 - val_loss: 0.3534\n",
            "Epoch 110/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5431 - val_loss: 0.6084\n",
            "Epoch 111/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0424 - val_loss: 0.4108\n",
            "Epoch 112/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6502 - val_loss: 0.3775\n",
            "Epoch 113/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9814 - val_loss: 0.3663\n",
            "Epoch 114/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9394 - val_loss: 0.5153\n",
            "Epoch 115/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7400 - val_loss: 0.8241\n",
            "Epoch 116/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7622 - val_loss: 0.6953\n",
            "Epoch 117/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1831 - val_loss: 0.8031\n",
            "Epoch 118/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7101 - val_loss: 0.8793\n",
            "Epoch 119/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9521 - val_loss: 0.4051\n",
            "Epoch 120/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6437 - val_loss: 0.4394\n",
            "Epoch 121/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8944 - val_loss: 0.3938\n",
            "Epoch 122/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8697 - val_loss: 0.2957\n",
            "Epoch 123/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.2753 - val_loss: 0.7444\n",
            "Epoch 124/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0978 - val_loss: 0.6240\n",
            "Epoch 125/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7912 - val_loss: 0.4999\n",
            "Epoch 126/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9580 - val_loss: 0.2676\n",
            "Epoch 127/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0254 - val_loss: 0.7227\n",
            "Epoch 128/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8741 - val_loss: 0.6707\n",
            "Epoch 129/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8382 - val_loss: 0.3120\n",
            "Epoch 130/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7640 - val_loss: 0.3918\n",
            "Epoch 131/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8427 - val_loss: 0.5693\n",
            "Epoch 132/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7329 - val_loss: 0.6266\n",
            "Epoch 133/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6272 - val_loss: 0.6969\n",
            "Epoch 134/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6900 - val_loss: 0.6606\n",
            "Epoch 135/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6061 - val_loss: 0.4288\n",
            "Epoch 136/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0013 - val_loss: 0.5063\n",
            "Epoch 137/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9737 - val_loss: 0.3393\n",
            "Epoch 138/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6246 - val_loss: 0.6337\n",
            "Epoch 139/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9013 - val_loss: 0.9701\n",
            "Epoch 140/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1219 - val_loss: 1.0863\n",
            "Epoch 141/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0966 - val_loss: 0.3107\n",
            "Epoch 142/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9304 - val_loss: 0.5953\n",
            "Epoch 143/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0381 - val_loss: 0.5687\n",
            "Epoch 144/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7049 - val_loss: 0.7935\n",
            "Epoch 145/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.7479 - val_loss: 0.5244\n",
            "Epoch 146/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1366 - val_loss: 0.9028\n",
            "Epoch 147/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1182 - val_loss: 0.5164\n",
            "Epoch 148/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.2490 - val_loss: 0.6605\n",
            "Epoch 149/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9402 - val_loss: 0.5841\n",
            "Epoch 150/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6852 - val_loss: 0.5839\n",
            "Epoch 151/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8986 - val_loss: 0.3275\n",
            "Epoch 152/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8811 - val_loss: 0.8418\n",
            "Epoch 153/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1783 - val_loss: 0.5942\n",
            "Epoch 154/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9892 - val_loss: 0.5502\n",
            "Epoch 155/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4737 - val_loss: 0.5953\n",
            "Epoch 156/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0869 - val_loss: 0.4095\n",
            "Epoch 157/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8220 - val_loss: 0.5458\n",
            "Epoch 158/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1291 - val_loss: 0.8547\n",
            "Epoch 159/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.4042 - val_loss: 0.3919\n",
            "Epoch 160/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0896 - val_loss: 0.5187\n",
            "Epoch 161/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9089 - val_loss: 0.7808\n",
            "Epoch 162/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7977 - val_loss: 0.4198\n",
            "Epoch 163/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7258 - val_loss: 0.4844\n",
            "Epoch 164/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6321 - val_loss: 0.3953\n",
            "Epoch 165/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9922 - val_loss: 0.3936\n",
            "Epoch 166/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9050 - val_loss: 0.6887\n",
            "Epoch 167/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8002 - val_loss: 0.3896\n",
            "Epoch 168/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1537 - val_loss: 0.3279\n",
            "Epoch 169/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6679 - val_loss: 1.0512\n",
            "Epoch 170/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7716 - val_loss: 0.5398\n",
            "Epoch 171/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6108 - val_loss: 0.4404\n",
            "Epoch 172/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.0158 - val_loss: 0.6875\n",
            "Epoch 173/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5663 - val_loss: 0.4766\n",
            "Epoch 174/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8333 - val_loss: 0.3553\n",
            "Epoch 175/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.2800 - val_loss: 0.3926\n",
            "Epoch 176/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5973 - val_loss: 0.5444\n",
            "Epoch 177/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9070 - val_loss: 0.6672\n",
            "Epoch 178/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6437 - val_loss: 0.5251\n",
            "Epoch 179/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9204 - val_loss: 0.3260\n",
            "Epoch 180/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7228 - val_loss: 0.4121\n",
            "Epoch 181/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6921 - val_loss: 0.7191\n",
            "Epoch 182/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7078 - val_loss: 0.4138\n",
            "Epoch 183/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8386 - val_loss: 0.2947\n",
            "Epoch 184/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6483 - val_loss: 0.4412\n",
            "Epoch 185/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5581 - val_loss: 0.5444\n",
            "Epoch 186/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9259 - val_loss: 0.5535\n",
            "Epoch 187/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8812 - val_loss: 0.4479\n",
            "Epoch 188/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6385 - val_loss: 0.3877\n",
            "Epoch 189/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7767 - val_loss: 0.4801\n",
            "Epoch 190/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7930 - val_loss: 0.3834\n",
            "Epoch 191/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6747 - val_loss: 0.6842\n",
            "Epoch 192/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5342 - val_loss: 0.3183\n",
            "Epoch 193/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9545 - val_loss: 0.5177\n",
            "Epoch 194/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7855 - val_loss: 0.9340\n",
            "Epoch 195/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9586 - val_loss: 0.7381\n",
            "Epoch 196/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9645 - val_loss: 0.3973\n",
            "Epoch 197/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.6574 - val_loss: 0.3799\n",
            "Epoch 198/400\n",
            "155/155 [==============================] - 6s 38ms/step - loss: 1.7251 - val_loss: 0.4735\n",
            "Epoch 199/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7756 - val_loss: 0.7384\n",
            "Epoch 200/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5536 - val_loss: 0.4340\n",
            "Epoch 201/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0092 - val_loss: 0.6006\n",
            "Epoch 202/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9375 - val_loss: 0.5618\n",
            "Epoch 203/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9158 - val_loss: 0.6285\n",
            "Epoch 204/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7603 - val_loss: 0.6174\n",
            "Epoch 205/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8611 - val_loss: 0.5591\n",
            "Epoch 206/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7201 - val_loss: 0.4905\n",
            "Epoch 207/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7545 - val_loss: 1.0497\n",
            "Epoch 208/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6640 - val_loss: 0.3614\n",
            "Epoch 209/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9398 - val_loss: 0.6897\n",
            "Epoch 210/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8255 - val_loss: 0.5864\n",
            "Epoch 211/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6686 - val_loss: 1.2015\n",
            "Epoch 212/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.2682 - val_loss: 1.0333\n",
            "Epoch 213/400\n",
            "155/155 [==============================] - 7s 43ms/step - loss: 1.8175 - val_loss: 0.4950\n",
            "Epoch 214/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6709 - val_loss: 0.5431\n",
            "Epoch 215/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5936 - val_loss: 0.3717\n",
            "Epoch 216/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.0951 - val_loss: 0.4238\n",
            "Epoch 217/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6283 - val_loss: 1.6327\n",
            "Epoch 218/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7183 - val_loss: 0.6401\n",
            "Epoch 219/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5843 - val_loss: 0.4256\n",
            "Epoch 220/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8972 - val_loss: 0.4688\n",
            "Epoch 221/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9646 - val_loss: 0.8068\n",
            "Epoch 222/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6458 - val_loss: 0.3682\n",
            "Epoch 223/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5672 - val_loss: 0.7854\n",
            "Epoch 224/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6648 - val_loss: 1.1382\n",
            "Epoch 225/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8474 - val_loss: 0.7741\n",
            "Epoch 226/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5163 - val_loss: 0.9066\n",
            "Epoch 227/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8047 - val_loss: 0.4251\n",
            "Epoch 228/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5803 - val_loss: 0.3475\n",
            "Epoch 229/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6708 - val_loss: 0.8500\n",
            "Epoch 230/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7953 - val_loss: 0.5793\n",
            "Epoch 231/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8893 - val_loss: 0.5206\n",
            "Epoch 232/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8393 - val_loss: 0.4567\n",
            "Epoch 233/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6337 - val_loss: 0.3181\n",
            "Epoch 234/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4431 - val_loss: 0.2920\n",
            "Epoch 235/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8308 - val_loss: 0.9870\n",
            "Epoch 236/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6364 - val_loss: 0.3454\n",
            "Epoch 237/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6846 - val_loss: 0.9744\n",
            "Epoch 238/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 2.1383 - val_loss: 0.2896\n",
            "Epoch 239/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7720 - val_loss: 0.4564\n",
            "Epoch 240/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5548 - val_loss: 0.5680\n",
            "Epoch 241/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6695 - val_loss: 0.2891\n",
            "Epoch 242/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6424 - val_loss: 1.0350\n",
            "Epoch 243/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6057 - val_loss: 0.6051\n",
            "Epoch 244/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 2.1513 - val_loss: 1.8500\n",
            "Epoch 245/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7905 - val_loss: 0.7969\n",
            "Epoch 246/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9119 - val_loss: 0.3786\n",
            "Epoch 247/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7179 - val_loss: 0.4147\n",
            "Epoch 248/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7649 - val_loss: 0.5258\n",
            "Epoch 249/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.3345 - val_loss: 0.4545\n",
            "Epoch 250/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9169 - val_loss: 0.8663\n",
            "Epoch 251/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7913 - val_loss: 0.4075\n",
            "Epoch 252/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8293 - val_loss: 0.3117\n",
            "Epoch 253/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7168 - val_loss: 0.7653\n",
            "Epoch 254/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6105 - val_loss: 0.3651\n",
            "Epoch 255/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8540 - val_loss: 0.5466\n",
            "Epoch 256/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6718 - val_loss: 0.5481\n",
            "Epoch 257/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6553 - val_loss: 0.3279\n",
            "Epoch 258/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7513 - val_loss: 0.9218\n",
            "Epoch 259/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8680 - val_loss: 0.7210\n",
            "Epoch 260/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7674 - val_loss: 0.9157\n",
            "Epoch 261/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5748 - val_loss: 0.3488\n",
            "Epoch 262/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8707 - val_loss: 0.3328\n",
            "Epoch 263/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7415 - val_loss: 0.4091\n",
            "Epoch 264/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6355 - val_loss: 0.5853\n",
            "Epoch 265/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5635 - val_loss: 0.3184\n",
            "Epoch 266/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8554 - val_loss: 0.5130\n",
            "Epoch 267/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.3426 - val_loss: 0.8710\n",
            "Epoch 268/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8357 - val_loss: 0.7700\n",
            "Epoch 269/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7861 - val_loss: 0.3210\n",
            "Epoch 270/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.8067 - val_loss: 0.7202\n",
            "Epoch 271/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9113 - val_loss: 0.2954\n",
            "Epoch 272/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9564 - val_loss: 1.1784\n",
            "Epoch 273/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5864 - val_loss: 0.4278\n",
            "Epoch 274/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7458 - val_loss: 0.5691\n",
            "Epoch 275/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8942 - val_loss: 0.6368\n",
            "Epoch 276/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4165 - val_loss: 0.5698\n",
            "Epoch 277/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.9374 - val_loss: 1.0258\n",
            "Epoch 278/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 2.0446 - val_loss: 0.4104\n",
            "Epoch 279/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6761 - val_loss: 0.3600\n",
            "Epoch 280/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4751 - val_loss: 0.3866\n",
            "Epoch 281/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.7060 - val_loss: 0.3188\n",
            "Epoch 282/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6953 - val_loss: 0.3830\n",
            "Epoch 283/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5278 - val_loss: 0.5690\n",
            "Epoch 284/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4771 - val_loss: 0.3575\n",
            "Epoch 285/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6726 - val_loss: 1.0315\n",
            "Epoch 286/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4616 - val_loss: 0.9069\n",
            "Epoch 287/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.4927 - val_loss: 0.3249\n",
            "Epoch 288/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4796 - val_loss: 0.4063\n",
            "Epoch 289/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3643 - val_loss: 0.4154\n",
            "Epoch 290/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4574 - val_loss: 0.4806\n",
            "Epoch 291/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 2.0038 - val_loss: 0.3216\n",
            "Epoch 292/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8550 - val_loss: 0.2727\n",
            "Epoch 293/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5894 - val_loss: 0.7793\n",
            "Epoch 294/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6937 - val_loss: 0.3712\n",
            "Epoch 295/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6623 - val_loss: 0.3398\n",
            "Epoch 296/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6966 - val_loss: 0.2915\n",
            "Epoch 297/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5231 - val_loss: 0.5248\n",
            "Epoch 298/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8404 - val_loss: 0.3792\n",
            "Epoch 299/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6912 - val_loss: 0.6937\n",
            "Epoch 300/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9028 - val_loss: 0.2995\n",
            "Epoch 301/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5229 - val_loss: 0.6805\n",
            "Epoch 302/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8025 - val_loss: 0.8356\n",
            "Epoch 303/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6094 - val_loss: 0.5058\n",
            "Epoch 304/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.4626 - val_loss: 0.4908\n",
            "Epoch 305/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3431 - val_loss: 0.3024\n",
            "Epoch 306/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.4307 - val_loss: 0.5490\n",
            "Epoch 307/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6761 - val_loss: 0.5042\n",
            "Epoch 308/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.8103 - val_loss: 0.4657\n",
            "Epoch 309/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4643 - val_loss: 0.6384\n",
            "Epoch 310/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.3770 - val_loss: 0.3056\n",
            "Epoch 311/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4817 - val_loss: 0.6895\n",
            "Epoch 312/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6172 - val_loss: 0.4271\n",
            "Epoch 313/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.9869 - val_loss: 0.3023\n",
            "Epoch 314/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6611 - val_loss: 1.0660\n",
            "Epoch 315/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4801 - val_loss: 0.3058\n",
            "Epoch 316/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7492 - val_loss: 0.3700\n",
            "Epoch 317/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7710 - val_loss: 0.6765\n",
            "Epoch 318/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.3941 - val_loss: 0.3835\n",
            "Epoch 319/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7953 - val_loss: 0.6138\n",
            "Epoch 320/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.4125 - val_loss: 0.5216\n",
            "Epoch 321/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6775 - val_loss: 0.3591\n",
            "Epoch 322/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3933 - val_loss: 0.2738\n",
            "Epoch 323/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.8457 - val_loss: 0.4788\n",
            "Epoch 324/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6898 - val_loss: 0.3086\n",
            "Epoch 325/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6937 - val_loss: 0.4027\n",
            "Epoch 326/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4539 - val_loss: 0.2986\n",
            "Epoch 327/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.4882 - val_loss: 0.4563\n",
            "Epoch 328/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6952 - val_loss: 0.7548\n",
            "Epoch 329/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5030 - val_loss: 0.3365\n",
            "Epoch 330/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4958 - val_loss: 0.4890\n",
            "Epoch 331/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7299 - val_loss: 0.8691\n",
            "Epoch 332/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.3896 - val_loss: 0.2460\n",
            "Epoch 333/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4711 - val_loss: 0.5302\n",
            "Epoch 334/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5676 - val_loss: 0.3942\n",
            "Epoch 335/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3903 - val_loss: 0.3868\n",
            "Epoch 336/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7094 - val_loss: 0.5443\n",
            "Epoch 337/400\n",
            "155/155 [==============================] - 7s 43ms/step - loss: 1.6020 - val_loss: 0.7461\n",
            "Epoch 338/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4854 - val_loss: 0.3231\n",
            "Epoch 339/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5669 - val_loss: 0.5153\n",
            "Epoch 340/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8936 - val_loss: 0.4114\n",
            "Epoch 341/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5191 - val_loss: 0.4815\n",
            "Epoch 342/400\n",
            "155/155 [==============================] - 7s 43ms/step - loss: 1.6108 - val_loss: 0.4864\n",
            "Epoch 343/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5642 - val_loss: 0.4335\n",
            "Epoch 344/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5792 - val_loss: 0.4555\n",
            "Epoch 345/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4213 - val_loss: 0.4047\n",
            "Epoch 346/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6182 - val_loss: 0.3770\n",
            "Epoch 347/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5446 - val_loss: 0.5239\n",
            "Epoch 348/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5306 - val_loss: 0.3036\n",
            "Epoch 349/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6240 - val_loss: 0.6311\n",
            "Epoch 350/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6177 - val_loss: 0.5234\n",
            "Epoch 351/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5214 - val_loss: 0.5019\n",
            "Epoch 352/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.9543 - val_loss: 0.5273\n",
            "Epoch 353/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4485 - val_loss: 0.3583\n",
            "Epoch 354/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5446 - val_loss: 0.7091\n",
            "Epoch 355/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7397 - val_loss: 0.3698\n",
            "Epoch 356/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4713 - val_loss: 0.4171\n",
            "Epoch 357/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7086 - val_loss: 0.6128\n",
            "Epoch 358/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.7539 - val_loss: 0.3676\n",
            "Epoch 359/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3716 - val_loss: 0.4641\n",
            "Epoch 360/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.3754 - val_loss: 0.5181\n",
            "Epoch 361/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6540 - val_loss: 0.5415\n",
            "Epoch 362/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.3184 - val_loss: 0.6739\n",
            "Epoch 363/400\n",
            "155/155 [==============================] - 7s 43ms/step - loss: 1.8568 - val_loss: 0.4838\n",
            "Epoch 364/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5712 - val_loss: 0.2359\n",
            "Epoch 365/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6566 - val_loss: 0.4058\n",
            "Epoch 366/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8883 - val_loss: 0.3450\n",
            "Epoch 367/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5877 - val_loss: 0.9270\n",
            "Epoch 368/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8245 - val_loss: 0.4904\n",
            "Epoch 369/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5988 - val_loss: 0.5081\n",
            "Epoch 370/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5506 - val_loss: 0.9558\n",
            "Epoch 371/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.8330 - val_loss: 0.5226\n",
            "Epoch 372/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4583 - val_loss: 0.5173\n",
            "Epoch 373/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.3518 - val_loss: 0.2877\n",
            "Epoch 374/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5751 - val_loss: 0.2811\n",
            "Epoch 375/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7122 - val_loss: 0.7442\n",
            "Epoch 376/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4134 - val_loss: 0.5447\n",
            "Epoch 377/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5211 - val_loss: 0.6113\n",
            "Epoch 378/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.7091 - val_loss: 0.3400\n",
            "Epoch 379/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.4722 - val_loss: 0.9362\n",
            "Epoch 380/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.6050 - val_loss: 1.0306\n",
            "Epoch 381/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.6967 - val_loss: 0.9000\n",
            "Epoch 382/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.9939 - val_loss: 0.4114\n",
            "Epoch 383/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5013 - val_loss: 0.6732\n",
            "Epoch 384/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.3881 - val_loss: 0.6559\n",
            "Epoch 385/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6223 - val_loss: 0.4139\n",
            "Epoch 386/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.4257 - val_loss: 0.4736\n",
            "Epoch 387/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.5727 - val_loss: 0.5650\n",
            "Epoch 388/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4560 - val_loss: 0.3419\n",
            "Epoch 389/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.3302 - val_loss: 0.3205\n",
            "Epoch 390/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.7515 - val_loss: 0.4871\n",
            "Epoch 391/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5686 - val_loss: 0.3195\n",
            "Epoch 392/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.5123 - val_loss: 1.1155\n",
            "Epoch 393/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.4923 - val_loss: 0.4113\n",
            "Epoch 394/400\n",
            "155/155 [==============================] - 9s 58ms/step - loss: 1.4928 - val_loss: 0.6795\n",
            "Epoch 395/400\n",
            "155/155 [==============================] - 6s 41ms/step - loss: 1.4260 - val_loss: 0.7234\n",
            "Epoch 396/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5926 - val_loss: 0.5239\n",
            "Epoch 397/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.5802 - val_loss: 0.7393\n",
            "Epoch 398/400\n",
            "155/155 [==============================] - 6s 39ms/step - loss: 1.4284 - val_loss: 0.3292\n",
            "Epoch 399/400\n",
            "155/155 [==============================] - 6s 42ms/step - loss: 1.6312 - val_loss: 0.6609\n",
            "Epoch 400/400\n",
            "155/155 [==============================] - 6s 40ms/step - loss: 1.6499 - val_loss: 0.9570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJpGOT8bAFax",
        "outputId": "a2e4790d-1a9f-4009-d614-6514a49ccc3c"
      },
      "source": [
        "call_model.evaluate(call_X_train, call_y_train, batch_size=4096)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 81ms/step - loss: 2.1128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1128334999084473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBvwCMVMBxOw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}